{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1iJvt7Vq_RDRldX9giofh1gG3KLxZoiza","authorship_tag":"ABX9TyPgTm7mzPrUpIt7Vebw7G+V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Git push**"],"metadata":{"id":"4XTfXYXJsqq2"}},{"cell_type":"code","source":["!apt-get install git -y\n","\n","# 2. Set Git config\n","!git config --global user.email \"vikramdev.iitd@gmail.com\"\n","!git config --global user.name \"Vikram Dev\"\n","\n","# 3. Clone the GitHub repo using personal access token\n","from getpass import getpass\n","token = getpass(\"Enter your GitHub PAT: \")\n","username = \"easyml-code\"\n","repo = \"Agentic-AI\"\n","\n","!git clone https://{token}@github.com/{username}/{repo}.git\n","%cd {repo}\n","\n","!cp -r \"/content/drive/MyDrive/Agentic_AI/AI_Agents\" ./ai_agents\n","# !cp \"/content/drive/MyDrive/Agentic_AI/AI_Agents/\" .\n","\n","!git add \"ai_agents\"\n","!git commit -m \"Added ai_agents.ipynb from Colab\"\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Zwvx5BVpwtAS","executionInfo":{"status":"ok","timestamp":1751405611632,"user_tz":-330,"elapsed":6202,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"98a84eb0-ee7c-4675-be11-f80fe16ccca7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git is already the newest version (1:2.34.1-1ubuntu1.12).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Enter your GitHub PAT: ··········\n","Cloning into 'Agentic-AI'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 17 (delta 3), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (17/17), 7.05 KiB | 7.05 MiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n","/content/Agentic-AI/Agentic-AI/Agentic-AI/Agentic-AI/Agentic-AI\n","[main 1a61907] Added ai_agents.ipynb from Colab\n"," 1 file changed, 1 insertion(+)\n"," create mode 100644 ai_agents/ai_agents\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (4/4), 5.96 KiB | 5.96 MiB/s, done.\n","Total 4 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n","remote: \n","remote: - GITHUB PUSH PROTECTION\u001b[K\n","remote:   —————————————————————————————————————————\u001b[K\n","remote:     Resolve the following violations before pushing again\u001b[K\n","remote: \n","remote:     - Push cannot contain secrets\u001b[K\n","remote: \n","remote:     \u001b[K\n","remote:      (?) Learn how to resolve a blocked push\u001b[K\n","remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n","remote:     \u001b[K\n","remote:     \u001b[K\n","remote:       —— Groq API Key ——————————————————————————————————————\u001b[K\n","remote:        locations:\u001b[K\n","remote:          - commit: 1a61907e3a63bfbf4b641d36253be42ea43a4bd9\u001b[K\n","remote:            path: ai_agents/ai_agents:1\u001b[K\n","remote:     \u001b[K\n","remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n","remote:        https://github.com/easyml-code/Agentic-AI/security/secret-scanning/unblock-secret/2zI4wAr1DsERukZ3qeXU7FmMDeC\u001b[K\n","remote:     \u001b[K\n","remote: \n","remote: \n","To https://github.com/easyml-code/Agentic-AI.git\n"," \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n","\u001b[31merror: failed to push some refs to 'https://github.com/easyml-code/Agentic-AI.git'\n","\u001b[m"]}]},{"cell_type":"markdown","source":["# 1. Simple Chat Agent Using Groq"],"metadata":{"id":"JPfOjZ7ar6Kf"}},{"cell_type":"code","source":["!pip install -q langchain-groq langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtGS0ZnK-CR5","executionInfo":{"status":"ok","timestamp":1751322769881,"user_tz":-330,"elapsed":9492,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"728bc8ea-2c49-492f-dad9-65c2ff7ec55c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from langchain_groq import ChatGroq"],"metadata":{"id":"NBMKhIK2sDMx","executionInfo":{"status":"ok","timestamp":1751322799383,"user_tz":-330,"elapsed":1628,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# What is ChatGroq?\n","# It's a BaseChatModel-derived class available in the langchain-groq integration that lets you communicate with\n","# Groq's open-source LLMs using a conversational/chat interface\n","\n","\n","llm = ChatGroq(model=\"llama3-70b-8192\",\n","              api_key=groq-api-key,\n","              temperature=0,\n","              max_tokens=1024\n","              )\n","\n","# Async:\n","#     Tool calling:\n","#         See ChatGroq.bind_tools() method for more.\n","\n","#     Structured output:\n","#         See ChatGroq.with_structured_output() for more."],"metadata":{"id":"sYQBXH6Ns1dg","executionInfo":{"status":"ok","timestamp":1751323182481,"user_tz":-330,"elapsed":141,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["response = llm.invoke(\"Explain how quantum computing works in simple terms.\")\n","print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pN4N_KvnyDIS","executionInfo":{"status":"ok","timestamp":1751323184821,"user_tz":-330,"elapsed":314,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"f4e5521a-777c-47ad-ec6d-92118ef30bee"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Quantum computing! It's a fascinating topic that can be tricky to grasp, but I'll try\n"]}]},{"cell_type":"markdown","source":["## 1.1. Adding personality to the chat agent"],"metadata":{"id":"HhHTHsS0BIbQ"}},{"cell_type":"code","source":["from langchain.schema import SystemMessage, HumanMessage\n","\n","# Add a system message to set personality\n","messages = [\n","    SystemMessage(content=\"You are a witty, sarcastic AI assistant who enjoys dark humor but stays helpful.\"),\n","    HumanMessage(content=\"What's the weather like in Delhi today?\")\n","]"],"metadata":{"id":"KeMA_Xzl_G08","executionInfo":{"status":"ok","timestamp":1751323630081,"user_tz":-330,"elapsed":41,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["response = llm.invoke(messages)\n","print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRx2axIVBekI","executionInfo":{"status":"ok","timestamp":1751323643568,"user_tz":-330,"elapsed":516,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"cd6233a7-c7e0-47ab-cbf0-c05b5d0d544c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Delhi, where the air is as toxic as my sense of humor. Just kidding, it's\n"]}]},{"cell_type":"markdown","source":["## 1.2. Adding memory to the chat agent"],"metadata":{"id":"IJGWeyQ-GFMU"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferMemory\n","from langchain.chains import ConversationChain"],"metadata":{"id":"KwNUm2fvGK7a","executionInfo":{"status":"ok","timestamp":1751325789540,"user_tz":-330,"elapsed":35,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Other Memory Types Available:\n","\n","| Memory Class                    | Description                             |\n","| ------------------------------- | --------------------------------------- |\n","| `ConversationBufferMemory`      | Full message history                    |\n","| `ConversationSummaryMemory`     | Summarizes past messages to save tokens |\n","| `ConversationTokenBufferMemory` | Keeps memory under a token limit        |\n"],"metadata":{"id":"XJxT00XBKLKc"}},{"cell_type":"code","source":["# Add memory (stores past messages)\n","memory = ConversationBufferMemory(return_messages=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xiFYiVkGKp-","executionInfo":{"status":"ok","timestamp":1751325870806,"user_tz":-330,"elapsed":35,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"90c6123f-b682-48e1-d266-b5a4de339ef2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-22-2785833832.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n","  memory = ConversationBufferMemory(return_messages=True)\n"]}]},{"cell_type":"code","source":["# Create a ConversationChain\n","chat = ConversationChain(\n","    llm=llm,\n","    memory=memory,\n","    verbose=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwKob7gvJ0hG","executionInfo":{"status":"ok","timestamp":1751325872593,"user_tz":-330,"elapsed":36,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"bafffdee-4fdb-4833-a6ef-3692e13fbae8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-23-2870551324.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n","  chat = ConversationChain(\n"]}]},{"cell_type":"code","source":["response1 = chat.predict(input=\"Hi, I'm Vikram.\")\n","response2 = chat.predict(input=\"What did I just tell you about myself?\")\n","print(\"Bot:\", response2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1SXRCwkJJ_cn","executionInfo":{"status":"ok","timestamp":1751325877330,"user_tz":-330,"elapsed":844,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"8a2053c5-d7ea-4459-fe21-606e42f908b2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","[]\n","Human: Hi, I'm Vikram.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","[HumanMessage(content=\"Hi, I'm Vikram.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Vikram! I'm LLaMA, an AI trained by a team\", additional_kwargs={}, response_metadata={})]\n","Human: What did I just tell you about myself?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Bot: You just told me your name, Vikram! That's all you've shared about yourself so far\n"]}]},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n","\n","\n","#Define your prompt with a personality (via SystemMessage)\n","prompt = ChatPromptTemplate.from_messages([\n","    SystemMessagePromptTemplate.from_template(\n","        \"You are a student counsellor who is supportive, empathetic, and motivating.\"\n","    ),\n","    MessagesPlaceholder(variable_name=\"history\"),\n","    HumanMessagePromptTemplate.from_template(\"{input}\")\n","])"],"metadata":{"id":"gbSRaFKEKVOG","executionInfo":{"status":"ok","timestamp":1751326612311,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#Create the conversation chain\n","chat_agent = ConversationChain(\n","    llm=llm,\n","    memory=memory,\n","    prompt=prompt,\n","    verbose=True\n",")"],"metadata":{"id":"CVEZhBKmKU9R","executionInfo":{"status":"ok","timestamp":1751326652804,"user_tz":-330,"elapsed":21,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["chat_agent.predict(input=\"Hi, I failed my exam.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"dYfRPo5lNAE4","executionInfo":{"status":"ok","timestamp":1751326669663,"user_tz":-330,"elapsed":361,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"b6b6edb8-fd7e-4c59-d48e-1c8c19357e8e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: You are a student counsellor who is supportive, empathetic, and motivating.\n","Human: Hi, I'm Vikram.\n","AI: Nice to meet you, Vikram! I'm LLaMA, an AI trained by a team\n","Human: What did I just tell you about myself?\n","AI: You just told me your name, Vikram! That's all you've shared about yourself so far\n","Human: Hi, I failed my exam.\n","AI: Vikram, I'm so sorry to hear that. Failing an exam can be really tough\n","Human: Hi, I failed my exam.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Vikram, I'm so sorry to hear that. Failing an exam can be really tough\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["chat_agent.predict(input=\"What should I do now?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"117_FyGoNH4f","executionInfo":{"status":"ok","timestamp":1751326701084,"user_tz":-330,"elapsed":428,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"80bd6d9d-8577-40a8-9c4e-e991134b2abd"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mSystem: You are a student counsellor who is supportive, empathetic, and motivating.\n","Human: Hi, I'm Vikram.\n","AI: Nice to meet you, Vikram! I'm LLaMA, an AI trained by a team\n","Human: What did I just tell you about myself?\n","AI: You just told me your name, Vikram! That's all you've shared about yourself so far\n","Human: Hi, I failed my exam.\n","AI: Vikram, I'm so sorry to hear that. Failing an exam can be really tough\n","Human: Hi, I failed my exam.\n","AI: Vikram, I'm so sorry to hear that. Failing an exam can be really tough\n","Human: What should I do now?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Vikram, first of all, take a deep breath and know that it's okay to feel\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["| AgentType                                   | Description                                                          |\n","| ------------------------------------------- | -------------------------------------------------------------------- |\n","| `AgentType.ZERO_SHOT_REACT`                 | Classic ReAct agent — plans and acts without prior examples          |\n","| `AgentType.OPENAI_FUNCTIONS`                | Uses OpenAI-style function/tool calling interface                    |\n","| `AgentType.CHAT_ZERO_SHOT_REACT`            | ReAct agent optimized for chat-based models                          |\n","| `AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT` | ReAct agent that returns structured tool outputs                     |\n","| `AgentType.OPENAI_MULTI_FUNCTIONS`          | Calls multiple tools in a single reasoning pass (multi-call capable) |\n"],"metadata":{"id":"B6yvjMryFK7o"}},{"cell_type":"code","source":["from langchain.agents import initialize_agent\n","from langchain.agents.agent_types import AgentType\n","from langchain.tools import Tool\n","\n","tools = [\n","    Tool(name=\"GetTime\", func=lambda _: \"It's always AI o'clock\", description=\"Tell the time\")\n","]\n","\n","agent = initialize_agent(\n","    tools=tools,\n","    llm=llm,\n","    agent=AgentType.OPENAI_FUNCTIONS,\n","    verbose=True,\n","    system_message=\"You're a pirate-themed assistant. Speak like a pirate!\"\n",")\n","\n","agent.invoke(\"What's the time?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"pPzqk0oBFP_k","executionInfo":{"status":"error","timestamp":1751324738920,"user_tz":-330,"elapsed":64,"user":{"displayName":"Vikram Dev","userId":"10536178294794993686"}},"outputId":"c27d0aab-306b-4744-e331-f0ad1cc92caa"},"execution_count":20,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"initialize_agent() missing 1 required positional argument: 'tools'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-20-3388545073.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m agent = initialize_agent(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAgentType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPENAI_FUNCTIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: initialize_agent() missing 1 required positional argument: 'tools'"]}]},{"cell_type":"code","source":["tavily_api_key=\"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\""],"metadata":{"id":"QcvTlWoOBgsN"},"execution_count":null,"outputs":[]}]}